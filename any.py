import os
import streamlit as st
from pydub import AudioSegment
import speech_recognition as sr
import tempfile

st.title("ğŸ§ ØªÙØ±ÙŠØº ØµÙˆØªÙŠ Ù…Ù† Ø£ÙŠ Ù…Ù„Ù ØµÙˆØªÙŠ Ø£Ùˆ ÙÙŠØ¯ÙŠÙˆ")

uploaded_file = st.file_uploader("ğŸ“¤ Ø§Ø±ÙØ¹ Ù…Ù„Ù ØµÙˆØªÙŠ Ø£Ùˆ ÙÙŠØ¯ÙŠÙˆ", type=["mp3","wav","m4a","ogg","flac","mp4","mov","avi","mkv"])

if uploaded_file:
    with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded_file.name)[1]) as temp_input:
        temp_input.write(uploaded_file.read())
        input_path = temp_input.name

    try:
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø¥Ù„Ù‰ wav Ø¨Ù…ÙˆØ§ØµÙØ§Øª Ù„Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØª
        sound = AudioSegment.from_file(input_path)
        sound = sound.set_channels(1).set_frame_rate(16000)
        wav_path = input_path + "_converted.wav"
        sound.export(wav_path, format="wav")
        
        recognizer = sr.Recognizer()
        chunk_length = 30 * 1000  # 30 Ø«Ø§Ù†ÙŠØ©
        total_length = len(sound)
        chunks = list(range(0, total_length, chunk_length))
        
        full_text = ""
        progress_text = st.empty()
        progress_bar = st.progress(0)

        for i, start in enumerate(chunks):
            end = min(start + chunk_length, total_length)
            chunk = sound[start:end]
            chunk_file = f"{wav_path}_chunk_{i}.wav"
            chunk.export(chunk_file, format="wav")
            
            with sr.AudioFile(chunk_file) as source:
                recognizer.adjust_for_ambient_noise(source, duration=0.5)
                audio = recognizer.record(source)
            
            try:
                text = recognizer.recognize_google(audio, language="ar")
                full_text += text + "\n"
            except sr.UnknownValueError:
                full_text += "[Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ø¬Ø²Ø¡]\n"
            except sr.RequestError:
                full_text += "[Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø®Ø¯Ù…Ø© Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØª]\n"
            
            os.remove(chunk_file)
            progress_text.text(f"ğŸ”¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¬Ø²Ø¡ {i+1} Ù…Ù† {len(chunks)}")
            progress_bar.progress((i+1)/len(chunks))

        st.success("âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø¨Ù†Ø¬Ø§Ø­!")
        st.text_area("ğŸ“„ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬:", value=full_text, height=400)
        st.download_button("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Øµ", data=full_text, file_name="transcription.txt")
        
        os.remove(input_path)
        os.remove(wav_path)

    except Exception as e:
        st.error(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù: {e}")